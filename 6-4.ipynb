{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59b37b3-9544-4b42-ba0a-57b68572507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network contains 14920 authors and 55466 collaborations\n",
      "\n",
      "=== Analysis Results ===\n",
      "Number of communities: 170\n",
      "Community size distribution:\n",
      "count     170.000000\n",
      "mean       87.764706\n",
      "std       139.160853\n",
      "min         2.000000\n",
      "25%         9.000000\n",
      "50%        29.000000\n",
      "75%       116.750000\n",
      "max      1130.000000\n",
      "Name: count, dtype: float64\n",
      "Modularity: 0.952 (Significant community structure)\n",
      "\n",
      "=== Degree Statistics ===\n",
      "Average degree: 7.44\n",
      "Max degree: 1147\n",
      "Top 5 authors by degree:\n",
      "  Author: https://openalex.org/A5059645286, Degree: 1147, Community: 60\n",
      "  Author: https://openalex.org/A5100749553, Degree: 501, Community: 23\n",
      "  Author: https://openalex.org/A5100320883, Degree: 431, Community: 50\n",
      "  Author: https://openalex.org/A5100343550, Degree: 347, Community: 92\n",
      "  Author: https://openalex.org/A5100435139, Degree: 309, Community: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\QMDownload\\miniconda3\\Lib\\site-packages\\networkx\\readwrite\\json_graph\\node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to author_communities_with_degree.csv\n",
      "\n",
      "Top 10 community sizes:\n",
      "Community 60: 1130 members\n",
      "Community 1: 804 members\n",
      "Community 23: 488 members\n",
      "Community 14: 486 members\n",
      "Community 50: 424 members\n",
      "Community 0: 368 members\n",
      "Community 92: 348 members\n",
      "Community 90: 302 members\n",
      "Community 104: 302 members\n",
      "Community 7: 292 members\n",
      "\n",
      "Degree distribution summary:\n",
      "Degree\n",
      "0         339\n",
      "1-4      6603\n",
      "5-9      6453\n",
      "10-19    1088\n",
      "20-49     327\n",
      "50-99      60\n",
      "100+       50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from community import community_louvain\n",
    "import netwulf as nw\n",
    "\n",
    "class DataProcessor:\n",
    "    @staticmethod\n",
    "    def sanitize_value(value):\n",
    "        \"\"\"确保所有数值符合JSON规范\"\"\"\n",
    "        try:\n",
    "            num = float(value)\n",
    "            if np.isinf(num):\n",
    "                return 1e308 if num > 0 else -1e308\n",
    "            if np.isnan(num):\n",
    "                return 0.0\n",
    "            return round(num, 6)\n",
    "        except:\n",
    "            return value\n",
    "\n",
    "    @staticmethod\n",
    "    def load_network(filepath):\n",
    "        \"\"\"加载并清洗网络数据\"\"\"\n",
    "        with open(filepath) as f:\n",
    "            raw_data = json.load(f)\n",
    "        \n",
    "        # 清洗节点数据\n",
    "        nodes = [{\n",
    "            'id': str(node.get('id', hash(json.dumps(node, sort_keys=True)))),\n",
    "            **{k: DataProcessor.sanitize_value(v) for k, v in node.items() if k != 'id'}\n",
    "        } for node in raw_data.get('nodes', [])]\n",
    "        \n",
    "        # 清洗边数据\n",
    "        edges = []\n",
    "        for edge in raw_data.get('edges', raw_data.get('links', [])):\n",
    "            source = str(edge.get('source', ''))\n",
    "            target = str(edge.get('target', ''))\n",
    "            if source and target:\n",
    "                edges.append({\n",
    "                    'source': source,\n",
    "                    'target': target,\n",
    "                    'weight': DataProcessor.sanitize_value(edge.get('weight', 1.0))\n",
    "                })\n",
    "        \n",
    "        return nodes, edges\n",
    "\n",
    "def build_network(nodes, edges):\n",
    "    \"\"\"构建网络图\"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # 添加节点\n",
    "    node_ids = {node['id'] for node in nodes}\n",
    "    for node in nodes:\n",
    "        G.add_node(node['id'], **{k:v for k,v in node.items() if k != 'id'})\n",
    "    \n",
    "    # 添加边\n",
    "    for edge in edges:\n",
    "        if edge['source'] in node_ids and edge['target'] in node_ids:\n",
    "            G.add_edge(edge['source'], edge['target'], weight=edge['weight'])\n",
    "    \n",
    "    return G\n",
    "\n",
    "# 主程序\n",
    "try:\n",
    "    # 1. 加载数据\n",
    "    nodes, edges = DataProcessor.load_network(\n",
    "        r'C:\\Users\\昳澄\\Desktop\\course\\DTU exchange\\computational social science\\讲座\\Computational_Social_Scientists_Network.json'\n",
    "    )\n",
    "    \n",
    "    # 2. 构建网络\n",
    "    G = build_network(nodes, edges)\n",
    "    print(f\"Network contains {G.number_of_nodes()} authors and {G.number_of_edges()} collaborations\")\n",
    "    \n",
    "    # 3. 社区检测\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    modularity = community_louvain.modularity(partition, G)\n",
    "    \n",
    "    # 4. 计算每个作者的度数\n",
    "    degrees = dict(G.degree())\n",
    "    \n",
    "    # 5. 结果分析\n",
    "    community_df = pd.DataFrame({\n",
    "        'Author': partition.keys(),\n",
    "        'Community': partition.values(),\n",
    "        'Degree': [degrees[author] for author in partition.keys()]\n",
    "    })\n",
    "    \n",
    "    # 按度数降序排列\n",
    "    community_df = community_df.sort_values('Degree', ascending=False)\n",
    "    \n",
    "    # 社区规模统计\n",
    "    size_distribution = community_df['Community'].value_counts()\n",
    "    \n",
    "    print(\"\\n=== Analysis Results ===\")\n",
    "    print(f\"Number of communities: {len(size_distribution)}\")\n",
    "    print(f\"Community size distribution:\\n{size_distribution.describe()}\")\n",
    "    print(f\"Modularity: {modularity:.3f} ({'Significant' if modularity > 0.3 else 'Insignificant'} community structure)\")\n",
    "    \n",
    "    # 输出度数统计信息\n",
    "    print(\"\\n=== Degree Statistics ===\")\n",
    "    print(f\"Average degree: {community_df['Degree'].mean():.2f}\")\n",
    "    print(f\"Max degree: {community_df['Degree'].max()}\")\n",
    "    print(f\"Top 5 authors by degree:\")\n",
    "    for idx, row in community_df.head(5).iterrows():\n",
    "        print(f\"  Author: {row['Author']}, Degree: {row['Degree']}, Community: {row['Community']}\")\n",
    "    \n",
    "    # 6. 可视化 - 修正参数问题\n",
    "    # 节点大小基于度数\n",
    "    nw.visualize(G, config={\n",
    "        'node': {\n",
    "            'color': {\n",
    "                'type': 'categorical',\n",
    "                'data': list(partition.values()),\n",
    "                'palette': 'tab20'\n",
    "            },\n",
    "            'size': {\n",
    "                'type': 'numerical',\n",
    "                'data': [min(20, 3 + degrees[n]/5) for n in G.nodes()],  # 将度数映射到合理的节点大小\n",
    "                'range': [3, 20]\n",
    "            }\n",
    "        },\n",
    "        'zoom': 0.85,\n",
    "        'physics': {\n",
    "            'barnesHut': {\n",
    "                'gravitationalConstant': -2000,\n",
    "                'springLength': 100,\n",
    "                'springConstant': 0.04\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # 7. 保存结果\n",
    "    community_df.to_csv('author_communities_with_degree.csv', index=False)\n",
    "    print(\"\\nResults saved to author_communities_with_degree.csv\")\n",
    "    \n",
    "    # 8. 打印最大社区的规模分布\n",
    "    top_communities = size_distribution.sort_values(ascending=False).head(10)\n",
    "    print(\"\\nTop 10 community sizes:\")\n",
    "    for i, (comm_id, size) in enumerate(top_communities.items()):\n",
    "        print(f\"Community {comm_id}: {size} members\")\n",
    "        \n",
    "    # 9. 度数分布统计\n",
    "    degree_counts = community_df['Degree'].value_counts().sort_index()\n",
    "    print(\"\\nDegree distribution summary:\")\n",
    "    bins = [0, 1, 5, 10, 20, 50, 100, float('inf')]\n",
    "    bin_labels = ['0', '1-4', '5-9', '10-19', '20-49', '50-99', '100+']\n",
    "    degree_binned = pd.cut(community_df['Degree'], bins=bins, labels=bin_labels)\n",
    "    print(degree_binned.value_counts().sort_index())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"Troubleshooting steps:\")\n",
    "    print(\"1. Verify JSON file contains both 'nodes' and 'edges'\")\n",
    "    print(\"2. Check sample data with:\")\n",
    "    print(\"import json; data=json.load(open('YOUR_FILE.json')); print('Keys:', data.keys())\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa90eb1-158d-4d5d-bd82-71e173fe7b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
